# ğŸ“Š StockChronicle

StockChronicle is an automated system for collecting, storing, and analyzing stock prices from the S&P 500, Dow Jones, and DAX indices.
Data is ingested daily into a PostgreSQL database and used for AI-based predictions as well as interactive dashboards.

---

## ğŸ“ Project Structure
```
StockChronicle/
â”‚â”€â”€ config/              # âœ… Configuration files
â”‚   â”œâ”€â”€ wikipedia_sources.yaml  # Index sources & validation counts
â”‚   â”œâ”€â”€ .env                    # Database credentials
â”‚â”€â”€ data/                # Raw data, CSVs, etc.
â”‚â”€â”€ notebooks/           # Jupyter Notebooks for analysis
â”‚â”€â”€ src/                 # Source code
â”‚   â”œâ”€â”€ etl/             # ETL scripts (Extract, Transform, Load)
â”‚   â”‚   â”œâ”€â”€ fetch_wiki_idx_corps.py  # Wikipedia data extraction script
â”‚   â”‚   â”œâ”€â”€ transform.py            # Data processing
â”‚   â”‚   â”œâ”€â”€ load_db.py              # Load data into Postgres
â”‚   â”œâ”€â”€ models/          # AI models for predictions
â”‚   â”œâ”€â”€ visualization/   # Dashboards & plots
â”‚   â”œâ”€â”€ utils/           # âœ… Reusable helper functions (e.g., logging, error handling)
â”‚   â”œâ”€â”€ db/              # âœ… Database connection handling
â”‚       â”œâ”€â”€ db_connection.py # Handles PostgreSQL connection
â”‚â”€â”€ tests/               # Unit tests
â”‚â”€â”€ .gitignore           # Files to ignore in Git
â”‚â”€â”€ environment.yml      # Conda environment dependencies
â”‚â”€â”€ requirements.txt     # Alternative for pip dependencies
â”‚â”€â”€ README.md            # Project documentation

```
---

## ğŸš€ Setup & Installation  

### **1ï¸âƒ£ Clone the repository**
```bash
git clone https://github.com/your-github-username/StockChronicle.git
cd StockChronicle
```

### **2ï¸âƒ£ Install required dependencies**
#### With Conda:
```bash
conda env create -f environment.yml
conda activate stockchronicle
```
#### With pip:
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Set up configuration files**
- Create a `.env` file in the `config` directory with your database credentials:
```
DB_USER=your_db_user
DB_PASSWORD=your_db_password
DB_HOST=your_db_host
DB_PORT=your_db_port
DB_NAME=your_db_name
```
- Adjust the `wikipedia_sources.yaml` file in the `config` directory to configure the desired indices and validation counts.

### **4ï¸âƒ£ Extract and load data**
- Run the `fetch_wiki_idx_corps.py` script to extract data from Wikipedia:
```bash
python src/etl/fetch_wiki_idx_corps.py
```
- Load the extracted data into the PostgreSQL database:
```bash
python src/etl/load_db.py
```

### **5ï¸âƒ£ Perform analysis and predictions**
- Use the Jupyter Notebooks in the `notebooks` directory to perform analysis and make predictions.

---

## ğŸ§ª Run tests
- Execute the unit tests in the `tests` directory:
```bash
pytest tests/
```

---

## ğŸ“„ License
This project is licensed under the MIT License. See the `LICENSE` file for more details.