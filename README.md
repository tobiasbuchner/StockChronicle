# ğŸ“Š StockChronicle

StockChronicle is an automated system for collecting, storing, and analyzing stock prices from the S&P 500, Dow Jones, and DAX indices.  
Data is ingested daily into a PostgreSQL database and used for AI-based predictions as well as interactive dashboards.

---

## ğŸ“ Project Structure
```
StockChronicle/
â”‚â”€â”€ config/              # Configuration files
â”‚   â”œâ”€â”€ config.yaml             # Centralized configuration file
â”‚   â”œâ”€â”€ .env                    # Database credentials
â”‚â”€â”€ data/                # Raw data, CSVs, etc.
â”‚   â”œâ”€â”€ wiki_corps/             # Extracted Wikipedia data
â”‚   â”œâ”€â”€ yfin_ohlc/              # Yahoo Finance OHLC data
â”‚   â”œâ”€â”€ yfin_company_data/      # Yahoo Finance company details
â”‚â”€â”€ logs/                # Log files
â”‚   â”œâ”€â”€ fetch_wiki_corps.log    # Logs for Wikipedia extraction
â”‚   â”œâ”€â”€ fetch_yfin_ohlc.log     # Logs for Yahoo Finance OHLC extraction
â”‚   â”œâ”€â”€ load_wiki_corps.log     # Logs for loading Wikipedia data into Postgres
â”‚â”€â”€ notebooks/           # Jupyter Notebooks for analysis
â”‚â”€â”€ src/                 # Source code
â”‚   â”œâ”€â”€ database/        # Database schema creation and management
â”‚   â”‚   â”œâ”€â”€ create_schema.py    # Script to create database schema
â”‚   â”œâ”€â”€ etl/             # ETL scripts (Extract, Transform, Load)
â”‚   â”‚   â”œâ”€â”€ fetch_wiki_corps.py  # Wikipedia data extraction script
â”‚   â”‚   â”œâ”€â”€ fetch_yfin_ohlc.py   # Yahoo Finance OHLC data extraction script
â”‚   â”‚   â”œâ”€â”€ fetch_company_info.py  # Yahoo Finance company details extraction script
â”‚   â”‚   â”œâ”€â”€ load_wiki_corps_postgres.py  # Load Wikipedia data into Postgres
â”‚   â”‚   â”œâ”€â”€ load_ohlc_postgres.py  # Load OHLC data into Postgres
â”‚   â”œâ”€â”€ models/          # AI models for predictions
â”‚   â”œâ”€â”€ visualization/   # Dashboards & plots
â”‚   â”œâ”€â”€ utils/           # Reusable helper functions
â”‚   â”‚   â”œâ”€â”€ logger.py           # Centralized logging setup
â”‚   â”‚   â”œâ”€â”€ db_utils.py         # Database utility functions
â”‚   â”‚   â”œâ”€â”€ config_loader.py    # YAML configuration loader
â”‚   â”‚   â”œâ”€â”€ file_utils.py       # File management utilities
â”‚â”€â”€ tests/               # Unit tests
â”‚â”€â”€ .gitignore           # Files to ignore in Git
â”‚â”€â”€ environment.yml      # Conda environment dependencies
â”‚â”€â”€ requirements.txt     # Alternative for pip dependencies
â”‚â”€â”€ README.md            # Project documentation
```

---

## ğŸš€ Setup & Installation  

### **1ï¸âƒ£ Clone the repository**
```bash
git clone https://github.com/your-github-username/StockChronicle.git
cd StockChronicle
```

### **2ï¸âƒ£ Install required dependencies**
#### With Conda:
```bash
conda env create -f environment.yml
conda activate stockchronicle
```
#### With pip:
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Set up configuration files**
- Create a `.env` file in the `config` directory with your database credentials:
```
DB_USER=your_db_user
DB_PASSWORD=your_db_password
DB_HOST=your_db_host
DB_PORT=your_db_port
DB_NAME=your_db_name
```
- Adjust the `config.yaml` file in the `config` directory to configure paths, cleanup settings, and data sources.

### **4ï¸âƒ£ Create the database schema**
- Run the `create_schema.py` script to create the required tables in the PostgreSQL database:
```bash
python src/database/create_schema.py
```

### **5ï¸âƒ£ Extract and load data**
#### Extract company data from Wikipedia:
```bash
python src/etl/fetch_wiki_corps.py
```
#### Load the extracted data into the PostgreSQL database:
```bash
python src/etl/load_wiki_corps_postgres.py
```
#### Extract OHLC (Open, High, Low, Close) data from Yahoo Finance:
```bash
python src/etl/fetch_yfin_ohlc.py
```
#### Extract company details from Yahoo Finance:
```bash
python src/etl/fetch_company_info.py
```
#### Load the OHLC data into the PostgreSQL database:
```bash
python src/etl/load_ohlc_postgres.py
```

### **6ï¸âƒ£ Perform analysis and predictions**
- Use the Jupyter Notebooks in the `notebooks` directory to perform analysis and make predictions:
```bash
jupyter notebook
```

---

## ğŸ§ª Run tests
- Execute the unit tests in the `tests` directory to ensure everything is working as expected:
```bash
pytest tests/
```

---

## ğŸ› ï¸ Key Features
- **Centralized Utilities**:
  - Logging: All scripts use a centralized logger from `logger.py`.
  - Configuration: All scripts load settings from `config.yaml` using `config_loader.py`.
  - Database Management: Database connections and queries are handled via `db_utils.py`.
  - File Management: File cleanup and other utilities are managed via `file_utils.py`.
- **Automated ETL Pipelines**:
  - Extract data from Wikipedia and Yahoo Finance, transform it, and load it into a PostgreSQL database.
- **AI-Powered Predictions**:
  - Use machine learning models to predict stock trends and prices.
- **Interactive Dashboards**:
  - Visualize stock data and predictions with interactive plots and dashboards.
- **Modular Design**:
  - Reusable components for logging, database management, and data validation.

---

## ğŸ“„ License
This project is licensed under the MIT License. See the `LICENSE` file for more details.

---

## ğŸ“ Support
If you encounter any issues or have questions, feel free to open an issue on GitHub or contact the project maintainer.

---

## ğŸŒŸ Contributing
Contributions are welcome! Please follow these steps:
1. Fork the repository.
2. Create a new branch for your feature or bug fix.
3. Commit your changes and push them to your fork.
4. Submit a pull request with a detailed description of your changes.

---

## ğŸ“š References
- [Wikipedia API Documentation](https://www.mediawiki.org/wiki/API:Main_page)
- [Yahoo Finance API Documentation](https://finance.yahoo.com/)
- [SQLAlchemy Documentation](https://docs.sqlalchemy.org/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)